from sklearn.tree import plot_tree
from  sklearn.preprocessing import LabelEncoder
from  sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from IPython.display import display
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

File_Path = 'D:/data/'
File_Name = 'car_data.csv'

df = pd.read_csv(File_Path + File_Name)

df.drop(columns=['User ID'], inplace=True)
encoders = []
for i in range (0, len (df.columns) -1):
    enc = LabelEncoder()
    df.iloc[:, i] = enc.fit_transform(df.iloc[:,i])
    encoders.append(enc)
x = df.iloc[:, 2:4]
y = df['Age']
x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=0)
model = DecisionTreeClassifier(criterion='entropy') #'gini'
model.fit(x,y)

x_pred = ['385','35','20000','No']
for i in range (0, len(df.columns) - 1):
    x_pred[i] = encoders[i].transfrom([x_pred[i]])
    x_pred_adj = np.array(x_pred).reshape(-1, 5)
    y_pred = model.predict(x_pred_adj)
    print('Predicion:', y_pred[0])
    score = model.score(x, y)
    print('Accuracy:', '{:.2}'.format(score))
    
feature = x.columns.tolist()
Data_class= y.tolist()

plt.figure(figsize=(25,20))
_ = plot_tree(model,
    feature_names = feature,
    class_name = Data_class,
    label='all',
    impurity = True,
    precision = 3,
    filled = True,
    rounded = True,
    fontsize = 16)
plt.show()

feature_importances = model.feature_importances_
feature_names = ['User ID','Gender','Age','AnnualSalary','Purchased']

sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.barplot(x= feature_importances, y = feature_names)

    print(feature_importances)